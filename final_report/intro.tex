\section{Introduction}\label{sec:intro}

With recent advances in computing technology, and new computing capabilities
with GPGPU hardware~\cite{owens2008gpu} and programming models~\cite{nvidia2007compute}, 
a trend of mapping many image processing applications on GPU is seen. 
Compute Unified Device Architecture (CUDA) has enabled mapping generic parallel
implementations of image processing algorithms~\cite{yang2008parallel} easier and benefits with good amount of 
performance and energy efficiency. 
Face detection is one such application which has lots of fine-grained
data parallelism available and exploit the execution resources of GPU.
It is processing of taking an image and detecting and locating the faces 
in the given image. It is an important application used world-wide for
public security, airports, video conferencing and video surveillance. 

Most of face detection systems today use cascade classifier algorithm 
based on Viola and Jones~\cite{viola2001rapid}. It has three important 
concepts tied to it -- integral image calculation, Adaboost classifier training
algorithm~\cite{freund1999short} and cascade classifier.  
Although, many of them have implemented these algorithm in CPUs, due to 
the inherent serial nature of CPU execution, you cannot get much of the
performance benefit and may not be able to meet hard real-time constraints,
even when executed on a multi-core CPU. 
With face detection algorithm's inherent parallel characteristics, GPGPU 
parallel computing substrate is a good candidate to gain performance benefits. 
With recent advances in NVIDIA CUDA programming model for scientific application 
acceleration~\cite{buck2007gpu}, we aim to use GPGPU execution model for accelerating face detection algorithm.

In this project, we have implemented the  face detection algorithm 
based on the Viola Jones classifier on GPU. 
As a starting point, we take the GNU licensed C++ program that has the 
algorithm implemented to detect faces in images. We also take the already trained 
classifier network which includes different HAAR classifier features trained based on thousands of images. 
We have identified the different  portions of the algorithm that 
can be parallelized and leverage the execution with abundant GPU resources efficiently. 
We have implemented all the three phases of the face detection -- nearest neighbor, integral image calculation and
scanning window stage along with classifying the output from each classifying stage. 
As a course project we limited the implementation to these 3 stages mentioned above, 
and not focus on the training of classifier itself. We take some insights and principles
based on previous implementations of face detection on GPGPUs, FPGA done here~\cite{kong2010gpu, sun2013acceleration, cho2009fpga}.
The main focus of this project was to gain performance benefits out of face detection acceleration and characterize
the bottlenecks if there are any. Based on those principles, we found many bottlenecks in the GPU implementation and add
optimizations to address these bottlenecks. We evaluate our GPU implementation performance with respect to single threaded CPU performance 
and we achieve a speedup upto 5.35x including the GPU inclusive time of copying.

We present the overview of our paper here:
Section \ref{sec:viola} explains the Viola Jones algorithm briefly and Section \ref{sec:impl} explains the our implementation of face detection.
Section \ref{sec:nnii} and Section{sec:haar} explain the three parallel versions of the algorithm we have implemented. Section\ref{sec:optim} details
the bottlenecks we came across in these kernels and explain the optimizations added and the benefits we get out of it. Section \ref{sec:eval} presents our evaluation framework
and Section \ref{sec:results} explains the detailed results including the performance and utilization factors. 
We finally end with conclusion in 
Section \ref{sec:conc}.


